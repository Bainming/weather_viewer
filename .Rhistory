group_by(course_id) |>
count |>
filter(n > 20) |>
arrange(-n)
# First, identify the most commonly taken courses in the student's first term for all students.
# This is relative to the student, not simply term=1.
# Define 'commonly taken' as over 20 first-term enrollments.
comm = a %>%
group_by(student_id) %>%
filter(term == min(term)) %>%
group_by(course_id) %>%
count %>%
filter(n > 20) %>%
arrange(-n)
# Second, compute the likelihood that a student majors in each of the three majors
# conditional on enrolling in the first term in each one of the classes identified above.
# Thus, you are computing 3 * number of classes probabilities.
ftrm = a %>%
group_by(student_id) %>%
filter(term == min(term)) # keep each student's 1st term data
major = data.frame()
for(cr in comm$course_id) {
tmp.major = ftrm %>%
filter(course_id == cr) %>%
group_by(student_id) %>%
slice(1) %>%
ungroup %>%
summarise(
course = cr,
major1 = mean(major_id == 1),
major2 = mean(major_id == 2),
major3 = mean(major_id == 3)
)
major = rbind(major, tmp.major)
}
# Third, make a visualization that shows the likelihood of majoring in each major (1,2,3)
# after taking each of the identified courses in the first term. Try to make a bar plot
# with stacked bars for each course and color fill shows the major distribution.
major_lng = gather(major, major, prob, 2:4)
ggplot(major_lng, aes(reorder(course, prob, max), prob, fill = major)) +
geom_bar(stat="identity") + coord_flip()
library(tidyverse)
load("info4100.hw.pathway.rda")
#######################################
####### BEGIN INPUT: Question 1 #######
#######################################
# (a) unique students
length(unique(a$student_id))
# (b) unique courses
length(unique(a$course_id))
# (c) unique terms
length(unique(a$term))
#######################################
#######################################
#######################################
####### BEGIN INPUT: Question 2 #######
#######################################
a %>% group_by(course_id) %>%
summarize(enrolled_count = n()) %>%
ungroup() %>%
arrange(desc(enrolled_count)) %>%
slice_head(n = 5)
#######################################
#######################################
#######################################
####### BEGIN INPUT: Question 3 #######
#######################################
a %>% group_by(course_id) %>%
summarize(enrolled_count = n()) %>%
ungroup() %>%
summarize(
num_popular_course = sum(enrolled_count > 30),
percent_popular_course = num_popular_course / n()
)
#######################################
#######################################
#######################################
####### BEGIN INPUT: Question 4 #######
#######################################
hist(a$grade, breaks = 20)
#######################################
#######################################
#######################################
####### BEGIN INPUT: Question 5 #######
#######################################
mean(a$grade)
#######################################
#######################################
tcp = a %>%
group_by(course_id) %>% filter(n() > 20) %>%
group_by(student_id, term) %>% filter(n() > 1)
pairs = data.frame()
#######################################
####### BEGIN INPUT: Question 6 #######
#######################################
# add your code here
for (sid in unique(tcp$student_id)) {
student_data <- tcp[tcp$student_id == sid, ]
for (t in unique(student_data$term)) {
term_data <- student_data[student_data$term == t, ]
courses <- term_data$course_id
combs <- combn(courses, 2)
new_pairs <- data.frame(
student_id = sid,
term = t,
course_id_1 = combs[1, ],
course_id_2 = combs[2, ]
)
pairs <- rbind(pairs, new_pairs)
}
}
#######################################
#######################################
head(pairs)
pairs$avg_grade = NA
#######################################
####### BEGIN INPUT: Question 7 #######
#######################################
# add your code here
tcp_cleaned <- tcp %>%
group_by(student_id, term, course_id) %>%
summarise(grade = mean(grade), .groups = "drop")
for (i in seq_len(nrow(pairs))) {
sid <- pairs$student_id[i]
term <- pairs$term[i]
cid1 <- pairs$course_id_1[i]
cid2 <- pairs$course_id_2[i]
g1 <- tcp_cleaned$grade[
tcp_cleaned$student_id == sid &
tcp_cleaned$term == term &
tcp_cleaned$course_id == cid1
]
g2 <- tcp_cleaned$grade[
tcp_cleaned$student_id == sid &
tcp_cleaned$term == term &
tcp_cleaned$course_id == cid2
]
pairs$avg_grade[i] <- mean(c(g1, g2))
}
#######################################
#######################################
head(pairs)
mean(pairs$avg_grade)
#######################################
####### BEGIN INPUT: Question 8 #######
#######################################
# add your code here
pairs_agg <- pairs %>%
filter(course_id_1 != course_id_2) %>%
mutate(
course_1 = pmin(course_id_1, course_id_2),
course_2 = pmax(course_id_1, course_id_2)
) %>%
group_by(course_1, course_2) %>%
summarise(
freq = n(),
paired_grade = mean(avg_grade, na.rm = TRUE),
.groups = "drop"
) %>%
filter(freq >= 20)
pairs_agg
#######################################
#######################################
pairs_agg$unpaired_grade = NA
#######################################
####### BEGIN INPUT: Question 9 #######
#######################################
# add your code here
for (i in 1:nrow(pairs_agg)) {
c1 <- pairs_agg$course_1[i]
c2 <- pairs_agg$course_2[i]
students_with_both <- a %>%
filter(course_id %in% c(c1, c2)) %>%
group_by(student_id) %>%
filter(n_distinct(course_id) == 2) %>%
group_by(student_id, course_id) %>%
summarise(term = min(term), grade = mean(grade), .groups = "drop") %>%
group_by(student_id) %>%
filter(n_distinct(term) == 2)
student_avg_grades <- students_with_both %>%
group_by(student_id) %>%
summarise(student_avg = mean(grade), .groups = "drop")
if (nrow(student_avg_grades) > 0) {
pairs_agg$unpaired_grade[i] <- mean(student_avg_grades$student_avg)
}
}
# Compare the paired and unpaired average grade for each course pair.
plot(pairs_agg$paired_grade, pairs_agg$unpaired_grade); abline(0,1)
#######################################
#######################################
#######################################
####### BEGIN INPUT: Question 10 ######
#######################################
# add your code here
diff <- pairs_agg %>%
mutate(diff = unpaired_grade - paired_grade) %>%
arrange(desc(diff))
diff
# Report the four pairs to avoid:
# add pairs here
# The top 4 are (946, 947), (8, 937), (185, 934), (1126, 25)
#######################################
#######################################
library(shiny); runApp('C:/Users/13282/Desktop/shiny/学习.R')
runApp('C:/Users/13282/Desktop/shiny/学习.R')
runApp('C:/Users/13282/Desktop/shiny/学习.R')
runApp('C:/Users/13282/Desktop/shiny/学习.R')
runApp('C:/Users/13282/Desktop/shiny/学习.R')
runApp('C:/Users/13282/Desktop/shiny/学习.R')
runApp('C:/Users/13282/Desktop/sts-3week/workshops/6C_app_nycflights/app0.R')
runApp('C:/Users/13282/Desktop/sts-3week/workshops/6C_app_nycflights/app0.R')
cd C:\Users\13282\Desktop\sts-3week\workshops\6C_app_nycflights
cd "C:\Users\13282\Desktop\sts-3week\workshops\6C_app_nycflights"
exists("writeRDS", envir = baseenv())
exists("writeRDS", envir = baseenv())
installr::updateR()
installr::updateR()
library(installr)
install.packages("installr")
library(installr)
updateR()
weather_2024 <- read.csv("data/weather.csv") |>
filter(str_starts(datetime, "2024"))
setwd("C:/Users/13282/Desktop/SYSEN-5460-Project-main")
weather_2024 <- read.csv("data/weather.csv") |>
filter(str_starts(datetime, "2024"))
library(stringr)
weather_2024 <- read.csv("data/weather.csv") |>
filter(str_starts(datetime, "2024"))
weather_2024 <- read.csv("data/weather.csv")
weather_2024 |> select(datetime)
library(dyplr)
library(dplyr)
weather_2024 |> select(datetime)
weather_2024 |> filter(str_starts(datetime, "2024"))
weather_2024 <- read.csv("data/weather.csv") |>
filter(str_starts(datetime, "2024"))
complement_sites <- read.csv("data/complement38.csv")
sites <- readRDS("data/sites.rds") |>
left_join(complement_sites, by = "aqs_id_full", suffix = c("", ".comp")) |>
mutate(site_name = if_else(is.na(site_name), Local.Site.Name, site_name)) |>
select(-c(Local.Site.Name, X))
sites <- readRDS("data/sites.rds") |>
left_join(complement_sites, by = "aqs_id_full", suffix = c("", ".comp")) |>
mutate(site_name = if_else(is.na(site_name), Local.Site.Name, site_name)) |>
select(-c(Local.Site.Name, X)) |>
writeRDS(sites, "data/complete_sites.rds")
sites <- readRDS("data/sites.rds") |>
left_join(complement_sites, by = "aqs_id_full", suffix = c("", ".comp")) |>
mutate(site_name = if_else(is.na(site_name), Local.Site.Name, site_name)) |>
select(-c(Local.Site.Name, X))
sites <- readRDS("data/sites.rds")
sites |>
left_join(complement_sites, by = "aqs_id_full", suffix = c("", ".comp")) |>
mutate(site_name = if_else(is.na(site_name), Local.Site.Name, site_name)) |>
select(-c(Local.Site.Name, X))
library(sf)
sites <- read_sf("data/sites.rds")
weather_2024 <- read.csv("data/weather.csv") |>
filter(str_starts(datetime, "2024"))
complement_sites <- read.csv("data/complement38.csv")
sites <- read_sf("data/sites.rds")
sites <- readRDS("data/sites.rds")
weather_2024 <- read.csv("data/weather.csv") |>
filter(str_starts(datetime, "2024"))
complement_sites <- read.csv("data/complement38.csv")
sites <- readRDS("data/sites.rds")
sites |>
left_join(complement_sites, by = "aqs_id_full", suffix = c("", ".comp")) |>
mutate(site_name = if_else(is.na(site_name), Local.Site.Name, site_name)) |>
select(-c(Local.Site.Name, X))
complete_sites <- sites |>
left_join(complement_sites, by = "aqs_id_full", suffix = c("", ".comp")) |>
mutate(site_name = if_else(is.na(site_name), Local.Site.Name, site_name)) |>
select(-c(Local.Site.Name, X))
glimpse(complete_sites)
library(readr)
write_rds(sites_complete, "data/sites_complete.rds")
write_rds(complete_sites, "data/complete_sites.rds")
complete_sites <- readRDS("C:/Users/13282/Desktop/SYSEN-5460-Project-main/data/complete_sites.rds")
View(complement_sites)
View(complete_sites)
glimpse(complete_sites)
# Define UI for application that draws a histogram
sites <- readRDS("data/complete_sites.rds")
weather_w_name <- read.csv("data/weather.csv") |>
left_join(
sites,
by = aqs_id_full,
)
View(complete_sites)
weather_w_name <- read.csv("data/weather.csv") |>
left_join(
data = sites,
by = 'aqs_id_full'
)
# Define UI for application that draws a histogram
sites <- readRDS("data/complete_sites.rds")
weather_w_name <- read.csv("data/weather.csv") |>
left_join(
sites,
by = 'aqs_id_full'
)
View(weather_2024)
View(weather_w_name)
View(weather_2024)
glimpse(sites)
weather_w_name <- read.csv("data/weather.csv")
glimpse(weather_w_name)
weather_w_name <- read.csv("data/weather.csv") |>
left_join(
sites,
by = 'aqs_id_full'
)
View(weather_w_name)
View(sites)
write.csv(weather_w_name, "data/weather_w_name")
View(weather_w_name)
write.csv(weather_w_name, "data/weather_w_name.csv")
weather <- read.csv("data/weather.csv")
weather_w_name <- read.csv("data/weather_w_name.csv")
View(weather_w_name)
weather_2024 <- read.csv("data/weather_w_name.csv") |>
filter(
str_starts(datetime, "2024")
)
View(weather_2024)
View(weather_w_name)
sites <- read_rds("data/complete_sites.rds")
View(sites)
View(weather_2024)
weather_2024 <- read.csv("data/weathe.csv") |>
filter(
str_starts(datetime, "2024")
)
weather_2024 <- read.csv("data/weather.csv") |>
filter(
str_starts(datetime, "2024")
)
sites <- read_rds("data/complete_sites.rds")
shiny::runApp('Weather_viz')
weather_2024 <- read.csv("data/weather.csv") |>
filter(
str_starts(datetime, "2024")
)
runApp()
View(weather_2024)
runApp()
View(weather_2024)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
View(weather_2024)
runApp()
# --- Data Loading and Preprocessing ---
weather_2024 <- read.csv("data/weather.csv") |>
mutate(
datetime_parsed = ymd_hms(datetime),
date = as.Date(datetime_parsed)
) |>
filter(year(datetime_parsed) == 2024, !is.na(temp))
runApp()
install.packages("bslib")
shiny::runApp()
runApp()
library(shiny)
library(dplyr)
library(readr)
library(stringr)
library(ggplot2)
library(lubridate)
library(bslib)
?cardHeader
??card_header
install.packages("shiny")
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp('v1.R')
runApp('v1.R')
View(complement_sites)
# Load site data
sites_sf <- readRDS("data/sites.rds")
sites_complement <- read_csv("data/complement38.csv", show_col_types = FALSE)
site_data <- st_drop_geometry(sites_sf)
site_data <- site_data %>%
left_join(sites_complement, by = "aqs_id_full") %>%
mutate(site_name = coalesce(site_name.x, site_name.y)) %>%
select(-site_name.x, -site_name.y)
View(site_data)
View(sites_complement)
View(sites_sf)
View(sites_complement)
View(site_data)
View(sites_complement)
sites_complement |> select(-aqs_id_full, site_name = Local.Site.Name)
sites_complement |> select(aqs_id_full, site_name = Local.Site.Name)
sites_complement |> select(aqs_id_full, site_name = Local.Site.Name) |>
write_csv("data/complement38.csv")
# Load site data
sites_sf <- readRDS("data/sites.rds")
sites_complement <- read_csv("data/complement38.csv", show_col_types = FALSE)Lo
sites_complement <- read_csv("data/complement38.csv", show_col_types = FALSE)
site_data <- site_data %>%
left_join(sites_complement, by = "aqs_id_full") %>%
mutate(site_name = coalesce(site_name.x, site_name.y)) %>%
select(-site_name.x, -site_name.y)
View(site_data)
View(sites_complement)
View(site_data)
View(sites_sf)
View(site_data)
View(sites_sf)
View(site_data)
# Load weather data
weather_df <- read_csv("data/weather.csv",
show_col_types = FALSE,
col_types = cols(datetime = col_character()))
# Process weather data
weather_df <- weather_df %>%
mutate(
datetime = parse_date_time(
datetime,
orders = c("ymd HMS z", "ymd HM z", "ymd H z", "ymd"),
tz = "UTC"
)
) %>%
filter(
datetime >= as_datetime("2024-01-01 00:00:00", tz = "UTC"),
datetime < as_datetime("2025-01-01 00:00:00", tz = "UTC")
) %>%
left_join(site_data, by = "aqs_id_full") %>%
mutate(
month = month(datetime, label = TRUE, abbr = FALSE),
hour = hour(datetime),
date = as_date(datetime)
)
runApp('v1.R')
runApp('v1_simp.R')
runApp('v1.R')
runApp('v1_simp.R')
View(weather_df)
View(weather_df)
runApp('v1_simp.R')
# Load and process weather data
weather_df <- read_csv("data/weather.csv", show_col_types = FALSE,
col_types = cols(datetime = col_character())) %>%
mutate(
datetime = parse_date_time(datetime,
orders = c("ymd HMS z", "ymd HM z", "ymd H z", "ymd"),
tz = "UTC"),
date = as_date(datetime),
month = month(datetime, label = TRUE, abbr = FALSE, locale = "C"),
hour = hour(datetime)
) %>%
filter(
datetime >= as_datetime("2024-01-01 00:00:00", tz = "UTC"),
datetime < as_datetime("2025-01-01 00:00:00", tz = "UTC"),
!is.na(temp),
!is.na(humidity)
) %>%
left_join(site_data, by = "aqs_id_full")
View(weather_df)
runApp('v1_simp.R')
View(site_data)
View(sites_complement)
View(site_data)
View(sites_complement)
View(sites_sf)
View(weather_df)
View(weather_df)
View(sites_sf)
View(sites_complement)
View(site_data)
runApp('v1_simp.R')
Sys.setlocale("LC_TIME", "en_US.UTF-8")
# Load and process weather data
weather_df <- read_csv("data/weather.csv", show_col_types = FALSE,
col_types = cols(datetime = col_character())) %>%
mutate(
datetime = parse_date_time(datetime,
orders = c("ymd HMS z", "ymd HM z", "ymd H z", "ymd"),
tz = "UTC"),
date = as_date(datetime),
month = month(datetime, label = TRUE, abbr = FALSE),
hour = hour(datetime)
) %>%
filter(
datetime >= as_datetime("2024-01-01 00:00:00", tz = "UTC"),
datetime < as_datetime("2025-01-01 00:00:00", tz = "UTC"),
!is.na(temp),
!is.na(humidity)
) %>%
left_join(site_data, by = "aqs_id_full")
View(weather_df)
runApp('v1_simp.R')
runApp('v1_simp.R')
runApp('v1_simp.R')
runApp('v1_simp.R')
runApp('v1_simp.R')
runApp('v1_simp.R')
